{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import shutil\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_path_to_datas_to_train = r\"C:\\Users\\Asus\\Documents\\Ship Classification\\flask\\input\\train\"\n",
    "Base_path_to_datas_to_val = r\"C:\\Users\\Asus\\Documents\\Ship Classification\\flask\\input\\valid\"\n",
    "Base_path_to_datas_to_test = r\"C:\\Users\\Asus\\Documents\\Ship Classification\\flask\\input\\test\"\n",
    "\n",
    "\n",
    "PIN_MEMORY=False\n",
    "#=======================================================================\n",
    "clas_of_img={}\n",
    "#=======================================================================\n",
    "results_dict = {}\n",
    "modeli=[]\n",
    "#=======================================================================\n",
    "torch.manual_seed(5017)\n",
    "torch.cuda.manual_seed(5017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_classes(path,class_dict):\n",
    "    for indx, path in enumerate(os.listdir(Base_path_to_datas_to_train)):\n",
    "        class_dict[indx] = path\n",
    "        \n",
    "        \n",
    "    return len(class_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Aircraft Carrier',\n",
       " 1: 'Bulkers',\n",
       " 2: 'Car Carrier',\n",
       " 3: 'Container Ship',\n",
       " 4: 'Cruise',\n",
       " 5: 'DDG',\n",
       " 6: 'Recreational',\n",
       " 7: 'Sailboat',\n",
       " 8: 'Submarine',\n",
       " 9: 'Tug'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Num_classes = gen_classes(Base_path_to_datas_to_train,clas_of_img)\n",
    "clas_of_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator# type: ignore\n",
    "from keras.applications.vgg16 import preprocess_input# type: ignore\n",
    "from tensorflow.keras.applications import VGG16# type: ignore\n",
    "     \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=45,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.5,\n",
    "    height_shift_range=0.5,\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8536 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_datagen.flow_from_directory(Base_path_to_datas_to_train, batch_size=32, target_size=(224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 942 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = train_datagen.flow_from_directory(Base_path_to_datas_to_val, batch_size=32,target_size=(224,224),shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 781 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(Base_path_to_datas_to_test, batch_size=32,target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Flatten,Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape,n_classes,optimizer='rmsprop'):\n",
    "    conv_base=VGG16(include_top=False,weights='imagenet',input_shape=input_shape)\n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "    top_model=conv_base.output\n",
    "    top_model=Flatten(name=\"flatten\")(top_model)\n",
    "    top_model=Dense(700,activation='relu')(top_model)\n",
    "    top_model=Dense(1272,activation='relu')(top_model)\n",
    "    top_model=Dropout(0,2)(top_model)\n",
    "    output_layer=Dense(n_classes, activation='softmax')(top_model)\n",
    "    model=Model(inputs=conv_base.input,outputs=output_layer)\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD# type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(224,224,3)\n",
    "optim=SGD(learning_rate=0.001)\n",
    "n_classes=10\n",
    "vgg_model=create_model(input_shape,n_classes,optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 700)               17562300  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1272)              891672    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1272)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                12730     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33181390 (126.58 MB)\n",
      "Trainable params: 18466702 (70.44 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "cp=ModelCheckpoint('best1.h5',monitor='val_loss',verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_28976\\3194689763.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history=vgg_model.fit_generator(generator=train_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "WARNING:tensorflow:From c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "266/266 [==============================] - ETA: 0s - loss: 1.9115 - accuracy: 0.5829\n",
      "Epoch 1: val_loss improved from inf to 1.35399, saving model to best1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 504s 2s/step - loss: 1.9115 - accuracy: 0.5829 - val_loss: 1.3540 - val_accuracy: 0.6455\n",
      "Epoch 2/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.9181 - accuracy: 0.7437\n",
      "Epoch 2: val_loss improved from 1.35399 to 1.11966, saving model to best1.h5\n",
      "266/266 [==============================] - 493s 2s/step - loss: 0.9181 - accuracy: 0.7437 - val_loss: 1.1197 - val_accuracy: 0.7284\n",
      "Epoch 3/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.7535 - accuracy: 0.7816\n",
      "Epoch 3: val_loss improved from 1.11966 to 0.98739, saving model to best1.h5\n",
      "266/266 [==============================] - 497s 2s/step - loss: 0.7535 - accuracy: 0.7816 - val_loss: 0.9874 - val_accuracy: 0.7532\n",
      "Epoch 4/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.6609 - accuracy: 0.8055\n",
      "Epoch 4: val_loss improved from 0.98739 to 0.93182, saving model to best1.h5\n",
      "266/266 [==============================] - 497s 2s/step - loss: 0.6609 - accuracy: 0.8055 - val_loss: 0.9318 - val_accuracy: 0.7522\n",
      "Epoch 5/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.6006 - accuracy: 0.8223\n",
      "Epoch 5: val_loss improved from 0.93182 to 0.77313, saving model to best1.h5\n",
      "266/266 [==============================] - 499s 2s/step - loss: 0.6006 - accuracy: 0.8223 - val_loss: 0.7731 - val_accuracy: 0.7780\n",
      "Epoch 6/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.5621 - accuracy: 0.8288\n",
      "Epoch 6: val_loss did not improve from 0.77313\n",
      "266/266 [==============================] - 491s 2s/step - loss: 0.5621 - accuracy: 0.8288 - val_loss: 0.8458 - val_accuracy: 0.7877\n",
      "Epoch 7/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.5071 - accuracy: 0.8478 \n",
      "Epoch 7: val_loss did not improve from 0.77313\n",
      "266/266 [==============================] - 4556s 17s/step - loss: 0.5071 - accuracy: 0.8478 - val_loss: 0.8325 - val_accuracy: 0.7899\n",
      "Epoch 8/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.4752 - accuracy: 0.8572\n",
      "Epoch 8: val_loss did not improve from 0.77313\n",
      "266/266 [==============================] - 497s 2s/step - loss: 0.4752 - accuracy: 0.8572 - val_loss: 0.7914 - val_accuracy: 0.7931\n",
      "Epoch 9/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.4617 - accuracy: 0.8604\n",
      "Epoch 9: val_loss improved from 0.77313 to 0.72455, saving model to best1.h5\n",
      "266/266 [==============================] - 495s 2s/step - loss: 0.4617 - accuracy: 0.8604 - val_loss: 0.7246 - val_accuracy: 0.8028\n",
      "Epoch 10/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.4274 - accuracy: 0.8670\n",
      "Epoch 10: val_loss did not improve from 0.72455\n",
      "266/266 [==============================] - 498s 2s/step - loss: 0.4274 - accuracy: 0.8670 - val_loss: 0.7364 - val_accuracy: 0.7985\n",
      "Epoch 11/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.4296 - accuracy: 0.8695\n",
      "Epoch 11: val_loss did not improve from 0.72455\n",
      "266/266 [==============================] - 493s 2s/step - loss: 0.4296 - accuracy: 0.8695 - val_loss: 0.7600 - val_accuracy: 0.8179\n",
      "Epoch 12/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.4082 - accuracy: 0.8739\n",
      "Epoch 12: val_loss improved from 0.72455 to 0.67709, saving model to best1.h5\n",
      "266/266 [==============================] - 493s 2s/step - loss: 0.4082 - accuracy: 0.8739 - val_loss: 0.6771 - val_accuracy: 0.8168\n",
      "Epoch 13/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.4060 - accuracy: 0.8778\n",
      "Epoch 13: val_loss did not improve from 0.67709\n",
      "266/266 [==============================] - 496s 2s/step - loss: 0.4060 - accuracy: 0.8778 - val_loss: 0.7473 - val_accuracy: 0.8244\n",
      "Epoch 14/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.8852\n",
      "Epoch 14: val_loss did not improve from 0.67709\n",
      "266/266 [==============================] - 605s 2s/step - loss: 0.3699 - accuracy: 0.8852 - val_loss: 0.6885 - val_accuracy: 0.8125\n",
      "Epoch 15/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8875\n",
      "Epoch 15: val_loss did not improve from 0.67709\n",
      "266/266 [==============================] - 531s 2s/step - loss: 0.3631 - accuracy: 0.8875 - val_loss: 0.6959 - val_accuracy: 0.8147\n",
      "Epoch 16/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.3617 - accuracy: 0.8865\n",
      "Epoch 16: val_loss improved from 0.67709 to 0.67395, saving model to best1.h5\n",
      "266/266 [==============================] - 515s 2s/step - loss: 0.3617 - accuracy: 0.8865 - val_loss: 0.6739 - val_accuracy: 0.8082\n",
      "Epoch 17/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.3463 - accuracy: 0.8882\n",
      "Epoch 17: val_loss improved from 0.67395 to 0.61995, saving model to best1.h5\n",
      "266/266 [==============================] - 511s 2s/step - loss: 0.3463 - accuracy: 0.8882 - val_loss: 0.6200 - val_accuracy: 0.8448\n",
      "Epoch 18/18\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.3514 - accuracy: 0.8906\n",
      "Epoch 18: val_loss did not improve from 0.61995\n",
      "266/266 [==============================] - 510s 2s/step - loss: 0.3514 - accuracy: 0.8906 - val_loss: 0.6582 - val_accuracy: 0.8308\n"
     ]
    }
   ],
   "source": [
    "epoch=18\n",
    "history=vgg_model.fit_generator(generator=train_set,\n",
    "                                steps_per_epoch=train_set.n//train_set.batch_size,\n",
    "                                validation_steps=validation_set.n//validation_set.batch_size,\n",
    "                                validation_data=validation_set,\n",
    "                                callbacks=[cp],\n",
    "                                epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "vgg_model.save('vgg16-ship-calssification.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
