{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import shutil\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_path_to_datas_to_train = r\"C:\\Users\\Asus\\Documents\\Ship Classification\\flask\\input\\train\"\n",
    "Base_path_to_datas_to_val = r\"C:\\Users\\Asus\\Documents\\Ship Classification\\flask\\input\\valid\"\n",
    "Base_path_to_datas_to_test = r\"C:\\Users\\Asus\\Documents\\Ship Classification\\flask\\input\\test\"\n",
    "\n",
    "\n",
    "PIN_MEMORY=False\n",
    "#=======================================================================\n",
    "clas_of_img={}\n",
    "#=======================================================================\n",
    "results_dict = {}\n",
    "modeli=[]\n",
    "#=======================================================================\n",
    "torch.manual_seed(5017)\n",
    "torch.cuda.manual_seed(5017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_classes(path,class_dict):\n",
    "    for indx, path in enumerate(os.listdir(Base_path_to_datas_to_train)):\n",
    "        class_dict[indx] = path\n",
    "        \n",
    "        \n",
    "    return len(class_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Aircraft Carrier',\n",
       " 1: 'Bulkers',\n",
       " 2: 'Car Carrier',\n",
       " 3: 'Container Ship',\n",
       " 4: 'Cruise',\n",
       " 5: 'DDG',\n",
       " 6: 'Recreational',\n",
       " 7: 'Sailboat',\n",
       " 8: 'Submarine',\n",
       " 9: 'Tug'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Num_classes = gen_classes(Base_path_to_datas_to_train,clas_of_img)\n",
    "clas_of_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator# type: ignore\n",
    "from keras.applications.vgg16 import preprocess_input# type: ignore\n",
    "from tensorflow.keras.applications import VGG16# type: ignore\n",
    "     \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=45,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.5,\n",
    "    height_shift_range=0.5,\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8536 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_datagen.flow_from_directory(Base_path_to_datas_to_train, batch_size=32, target_size=(224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 942 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = train_datagen.flow_from_directory(Base_path_to_datas_to_val, batch_size=32,target_size=(224,224),shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 781 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(Base_path_to_datas_to_test, batch_size=32,target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model=load_model(r'C:\\Users\\Asus\\Documents\\Ship Classification\\flask\\notebook\\vgg16-ship-calssification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "print(validation_set.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 52s 2s/step - loss: 0.6748 - accuracy: 0.8217\n",
      "[0.6747666597366333, 0.8216560482978821]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(validation_set)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 42s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.07      0.06        59\n",
      "           1       0.11      0.15      0.13        97\n",
      "           2       0.16      0.16      0.16        95\n",
      "           3       0.18      0.17      0.18        86\n",
      "           4       0.05      0.04      0.05        45\n",
      "           5       0.08      0.04      0.05       102\n",
      "           6       0.15      0.24      0.19        89\n",
      "           7       0.05      0.05      0.05        74\n",
      "           8       0.09      0.08      0.08        66\n",
      "           9       0.15      0.07      0.10        68\n",
      "\n",
      "    accuracy                           0.12       781\n",
      "   macro avg       0.11      0.11      0.10       781\n",
      "weighted avg       0.11      0.12      0.11       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_set)  # Get predictions\n",
    "predictions = np.argmax(predictions, axis=1)  # Get predicted classes\n",
    "\n",
    "ground_truth = test_set.classes  # Get ground truth labels\n",
    "\n",
    "# Calculate confusion matrix\n",
    "from sklearn.metrics import classification_report\n",
    "cm = classification_report(ground_truth, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 59s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83        74\n",
      "           1       0.73      0.78      0.76       106\n",
      "           2       0.92      0.94      0.93       179\n",
      "           3       0.95      0.89      0.92        82\n",
      "           4       0.92      0.97      0.95        72\n",
      "           5       0.81      0.86      0.83        84\n",
      "           6       0.75      0.72      0.74        89\n",
      "           7       0.68      0.81      0.74        74\n",
      "           8       0.92      0.93      0.92        72\n",
      "           9       0.85      0.57      0.68       110\n",
      "\n",
      "    accuracy                           0.83       942\n",
      "   macro avg       0.83      0.84      0.83       942\n",
      "weighted avg       0.84      0.83      0.83       942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(validation_set)  # Get predictions\n",
    "predictions = np.argmax(predictions, axis=1)  # Get predicted classes\n",
    "\n",
    "ground_truth = validation_set.classes  # Get ground truth labels\n",
    "\n",
    "# Calculate confusion matrix\n",
    "from sklearn.metrics import classification_report\n",
    "cm = classification_report(ground_truth, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image# type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n",
      "Cruise\n"
     ]
    }
   ],
   "source": [
    "img=image.load_img(r'C:\\Users\\Asus\\Documents\\Ship Classification\\flask\\input\\Disney-Treasure-Exterior-2-1-1.jpg',target_size=(224,224))\n",
    "img=image.img_to_array(img)\n",
    "img=img.reshape((1,img.shape[0],img.shape[1],img.shape[2]))\n",
    "img=preprocess_input(img)\n",
    "pred=model.predict(img)\n",
    "pred=pred.flatten()\n",
    "pred=list(pred)\n",
    "n=max(pred)\n",
    "val_dict={0: 'Aircraft Carrier',\n",
    " 1: 'Bulkers',\n",
    " 2: 'Car Carrier',\n",
    " 3: 'Container Ship',\n",
    " 4: 'Cruise',\n",
    " 5: 'DDG',\n",
    " 6: 'Recreational',\n",
    " 7: 'Sailboat',\n",
    " 8: 'Submarine',\n",
    " 9: 'Tug'}\n",
    "result=val_dict[pred.index(n)]\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
